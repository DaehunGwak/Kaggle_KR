{
  "cells": [
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "f57e59e8589cb94001d8673fb737a4e0d96852bd",
        "_cell_guid": "dbf2ff22-712b-4fc2-8687-99caa9bf07d8",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 이 Python 3 environment는 많은 유용한 분석 libraires의 설치와 함께합니다. \n# This Python 3 environment comes with many helpful analytics libraries installed\n\n# 이는 kaggle/python docker image로 정의되어 있습니다 : https://github.com/kaggle/docker-python\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n# 예시로, load해서 사용해볼만한 몇가지의 유용한 packages들을 보여드리겠습니다.\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra (선형대수학)\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) (데이터 처리, CSV file의 I/O)\n\n# Input data files는 \"../input/\" directory를 통해 제공됩니다.\n# Input data files are available in the \"../input/\" directory.\n\n# 예를 들면, 이것을 실행시키면 (run을 누르거나, Shift+Enter를 누르세요) input directory에 있는 file들을 보여줄 것입니다.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# 현재 directory에 쓴 모든 results들은 output 형태로 저장될 것입니다.\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "113b5b8f58952300f5a35a3999788e2d076beeab",
        "_cell_guid": "2805f6da-0df3-41f1-977a-547dac26a11f"
      },
      "cell_type": "markdown",
      "source": "이 kernel은 Keras를 위해 CNN을 구현하고 싶어하는 초심자들을 위한 것입니다. 이 kernel을 이용하면, 당신은 좋은 점수를 받기를 기대할 수 있을 뿐만 아니라 keras에 대해서도 배울 수 있습니다.\nKeras는 model을 initialize하고 우리가 원하는 layer를 계속 쌓을 수 있는 간단한 frameworks 입니다. 이것은 deep neural networks를 아주 쉽게 만들 수 있도록 도와줍니다.\n\n(This kernel is specifically is for Beginners who want's to experiment building CNN using Keras. By using this kernel, you can expect to get good score and also learn keras. \nKeras is simple frameworks where we can initialize the model and keep stacking the layers we want. It makes building deep neural networks very easy.)"
    },
    {
      "metadata": {
        "_uuid": "58c82d3b3c4b4305b388a6ac4eeca49d600f9105",
        "_cell_guid": "ea3f4874-a9aa-42f1-9605-b1784a6f48ba",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom os.path import join as opj\nfrom matplotlib import pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport pylab\nplt.rcParams['figure.figsize'] = 10, 10\n%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7a7f3af5ef279a9ed26c4d9ee764bd1fb4bdf10e",
        "_cell_guid": "804d3969-9035-4ceb-bb65-1b8549d729ec",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Load the data.\ntrain = pd.read_json(\"../input/train.json\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2c18cf164fbbc6d1c29e9c668cbfcd7a1ea10824",
        "_cell_guid": "7b546aab-7b7d-4cde-91cc-e794fd4041bd",
        "trusted": true
      },
      "cell_type": "code",
      "source": "test = pd.read_json(\"../input/test.json\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f5b6c2ba24e6bf5726f8551cdeeeaf931184c2bc",
        "_cell_guid": "e178779f-0698-47cd-9be5-50f9c9590089"
      },
      "cell_type": "markdown",
      "source": "#데이터에 대한 기본 설명\n#Intro about the Data.\n\nSentinel 인공위성은 지구에서 680Km 떨어진 지점에 위치해 있습니다. 특정 입사각에서 신호들을 보내, 돌아오는 신호를 기록합니다. 기본적으로 반사되어 되돌아온 신호는 \"backscatter\"이라고 불립니다. 우리에게 주어진 데이터는 backscatter 변수로 전통적인 backscatter 변수의 형태를 띕니다. 그 형태는 다음과 같습니다 : \n(Sentinet -1 sat is at about 680 Km above earth. Sending pulses of signals at a particular angle of incidence and then recoding it back. Basically those reflected signals are called backscatter. The data we have been given is backscatter coefficient which is the conventional form of backscatter coefficient given by:)\n\n$σo (dB) = βo (dB) + 10log10 [ sin(ip) / sin (ic)] $\n\n1. ip = 특정 pixel에서의 입사각\n2. ic = 이미지 중심에서의 입사각\n3. K = 상수\n\n(where\n1. ip=is angle of incidence for a particular pixel\n2. 'ic ' is angle of incidence for center of the image\n3. K =constant.)\n\n데이터에는 $σo$가 직접적으로 제공됩니다.\nWe have been given $σo$ directly in the data.\n\n###$σo$의 특징\n기본적으로 σo는 signal이 어느 표면에서 산란되었는지에 따라 다릅니다. 예를 들어, 어떤 특정한 입사각에 대해 다음과 같은 다른 형태를 나타냅니다 : \n(Basically σo varies with the surface on which the signal is scattered from. For example, for a particular angle of incidence, it varies like:)\n\n*             WATER...........           SETTLEMENTS........           AGRICULTURE...........          BARREN........\n\n1.**HH:**     -27.001   ................                     2.70252       .................                -12.7952        ................    -17.25790909\n\n2.**HV: **      -28.035      ................            -20.2665             ..................          -21.4471       .................     -20.019\n\n위에서 보다싶이, HH 구성 요소들은 변화가 크지만, HV는 그렇지 않습니다.\n**저는 배에서 산란한 데이터는 갖고 있지 않습니다. 하지만 금속 물체임에 따라, 이것은 얼음 물체와는 다른 형태로 변화해야 합니다.**\n(As you can see, the HH component varies a lot but HV doesn't.\n**I don't have the data for scatter from ship, but being a metal object, it should vary differently as compared to ice object.**)\n\n###HH와 HV는 무엇입니까?\n이 Sentinel 인공위성은 RISTSAT 인공위성 (인도의 원격탐사 인공위성)과 같으며, 그것들은 ping들을 수평 편광(H polarization)으로만 보냅니다 **(수직 편광(V polarization)으로는 보내지 않습니다.)**.  그 H-pings들은 산란되며,  물체들은 그것들의 편광상태를 변경시키게 되고,  H와 V의 혼합으로 반환됩니다.\n**Sentinal이 오직 H-송신기 만을 가짐에 따라, 돌아오는 신호는 HH와 HV 형태만 존재합니다.**. 왜 VV가 제공되지 않았는지 물어보지 마십시오(왜냐하면 Sentinel은 V-ping 송신기를 갖고 있지 않습니다).\n\n이제 feature를 봅시다. 이 데모 코드의 목적은 RGB와 비슷한 3-channel 데이터를 만들기 위해, 두개의 band(HH, HV)를 추출한 후 그것들을 평균을 낸 것을 3rd channel으로 사용할 것입니다.\n\n(Ok, so this Sentinel Settalite is equivalent to RISTSAT(an Indian remote sensing Sat) and they only Transmit pings in H polarization, **AND NOT IN V polarization**.  Those H-pings gets scattered, objects change their polarization and returns as a mix of H and V.\n**Since Sentinel has only H-transmitter, return signals are of the form of HH and HV only**. Don't ask why VV is not given(because Sentinel don't have V-ping transmitter).\n\nNow coming to features, for the purpose of this demo code, I am extracting all two bands and taking avg of them as 3rd channel to create a 3-channel RGB equivalent. )\n"
    },
    {
      "metadata": {
        "_uuid": "5292632717f11cd01c135dfabfd3cda9318cc639",
        "_cell_guid": "829bf7db-fab1-4a2d-9562-0a37c6390d2a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# training 데이터를 만듭니다.\n# HH, HV, HH와 HV의 평균 총 3개의 band를 만듭니다. \n#Generate the training data\n#Create 3 bands having HH, HV and avg of both\nX_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\nX_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\nX_train = np.concatenate([X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis],((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], axis=-1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "01b69c50c6425d7d35b9bbefca7c06ea4bf1214b",
        "_cell_guid": "a95eedd5-fc75-4834-a817-e3ad700923f5",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#빙산을 봅시다\n#Take a look at a iceberg\nimport plotly.offline as py\nimport plotly.graph_objs as go\npy.init_notebook_mode(connected=True)\ndef plotmy3d(c, name):\n    print(c.shape)\n    data = [\n        go.Surface(\n            z=c\n        )\n    ]\n    layout = go.Layout(\n        title=name,\n        autosize=False,\n        width=700,\n        height=700,\n        margin=dict(\n            l=65,\n            r=50,\n            b=65,\n            t=90\n        )\n    )\n    fig = go.Figure(data=data, layout=layout)\n    py.iplot(fig)\nplotmy3d(X_band_1[12,:,:], 'iceberg')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1c65412c80ff504df19d55aa14093ebcd1028e6a",
        "_cell_guid": "cd7ea3c1-f039-445e-b5da-adfb608930d7"
      },
      "cell_type": "markdown",
      "source": "멋진 빙산이 보이네요. 레이더 데이터에서 빙산의 모양은 여기서 보이는 것과  같은 산 모양을 나타낼 것입니다. 이것이 실제 이미지가 아닌 레이더에서 산란된 결과임에 따라, 이것처럼 뾰족한 봉우리와 왜곡된 모양으로 나타날 것입니다. 배의 모양은 점, 혹은 연장된 점처럼 보일 것입니다. 여기에서 둘의 구조상의 차이점이 나타나고, 우리는 CNN을 이용하여 이 차이점을 활용할 수 있습니다. 우리가 레이더로부터 얻은 backscatter를 이용하여 합성 사진을 만들 수 있다면, 많은 도움이 될 것입니다.  \n(That's a cool looking iceberg we have. Remember, in radar data, the shape of the iceberg is going to be like a mountain as shown in here. Since this is not a actual image but scatter from radar, the shape is going to have peaks and distortions like these. The shape of the ship is going to be like a point, may be like a elongated point. From here the structural differences arise and we can exploit those differences using a CNN. It would be helpful if we can create composite images using the backscatter from radar.)"
    },
    {
      "metadata": {
        "collapsed": true,
        "scrolled": false,
        "_uuid": "ab163fd947f3f108eacb0d367bf62505b0b9df9b",
        "_cell_guid": "f78d43c6-c83e-47e3-a279-4dc8d3481c6c",
        "trusted": false
      },
      "cell_type": "code",
      "source": "plotmy3d(X_band_1[14,:,:], 'Ship')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f907f993a1c63f4519872ecb381021c1a0dce2ca",
        "_cell_guid": "1e2a6f33-992a-435e-be65-5ee614e6f7ba"
      },
      "cell_type": "markdown",
      "source": "이것이 배입니다, 연결되어 있는 점같이 생겼네요. 배 모양을 시각화하기엔 해상도가 부족합니다. 그것을 도와주기위해 CNN이 존재합니다. 배-빙산 분류에 관련된 논문이 다음과 같이 존재합니다:\nhttp://elib.dlr.de/99079/2/2016_BENTES_Frost_Velotto_Tings_EUSAR_FP.pdf\n그런데 그들의 데이터는 훨씬 좋은 해상도를 갖고 있기 때문에 그들이 이용한 CNN은 여기에 맞지 않을 것 같습니다.\n\nThat's a ship, looks like a elongated point. We don't have much resolution in images to visualize the shape of the ship. However CNN is here to help. There are few papers on ship iceberg classification like this:\nhttp://elib.dlr.de/99079/2/2016_BENTES_Frost_Velotto_Tings_EUSAR_FP.pdf\nHowever their data have much better resolution so I don't  feel that the CNN they used would be suitable here."
    },
    {
      "metadata": {
        "_uuid": "906b685c8ab2b91b3b9e4baffb65ad1c1aa028c3",
        "_cell_guid": "6c0c41e0-b95e-4129-a95e-06cd6808553d"
      },
      "cell_type": "markdown",
      "source": "다시 돌아가서 Keras로 CNN을 만들어 봅시다. 다른 framework보다 훨씬 좋습니다. 당신도 좋아할 거에요.\n(Get back to building a CNN using Keras. Much better frameworks then others. You will enjoy for sure.)"
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "7a68a94f8c617209dfe56a58e291193e963d0f62",
        "_cell_guid": "fb15bc53-becc-4e87-88ce-3bc99d45358d",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Import Keras.\nfrom matplotlib import pyplot\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.merge import Concatenate\nfrom keras.models import Model\nfrom keras import initializers\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "4602792c9d531903bd65c3b127a1e6be2c444b2d",
        "_cell_guid": "d7a4c0cc-0e96-46ea-960c-89bb80e11b56",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#define our model\ndef getModel():\n    #Building the model\n    gmodel=Sequential()\n    #Conv Layer 1\n    gmodel.add(Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 3)))\n    gmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n    gmodel.add(Dropout(0.2))\n\n    #Conv Layer 2\n    gmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu' ))\n    gmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    gmodel.add(Dropout(0.2))\n\n    #Conv Layer 3\n    gmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n    gmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    gmodel.add(Dropout(0.2))\n\n    #Conv Layer 4\n    gmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n    gmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    gmodel.add(Dropout(0.2))\n\n    #Flatten the data for upcoming dense layers\n    gmodel.add(Flatten())\n\n    #Dense Layers\n    gmodel.add(Dense(512))\n    gmodel.add(Activation('relu'))\n    gmodel.add(Dropout(0.2))\n\n    #Dense Layer 2\n    gmodel.add(Dense(256))\n    gmodel.add(Activation('relu'))\n    gmodel.add(Dropout(0.2))\n\n    #Sigmoid Layer\n    gmodel.add(Dense(1))\n    gmodel.add(Activation('sigmoid'))\n\n    mypotim=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n    gmodel.compile(loss='binary_crossentropy',\n                  optimizer=mypotim,\n                  metrics=['accuracy'])\n    gmodel.summary()\n    return gmodel\n\n\ndef get_callbacks(filepath, patience=2):\n    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n    msave = ModelCheckpoint(filepath, save_best_only=True)\n    return [es, msave]\nfile_path = \".model_weights.hdf5\"\ncallbacks = get_callbacks(filepath=file_path, patience=5)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "a883659e53709da950d04a4e5349c66d77a9422f",
        "_cell_guid": "1d690d4a-09ca-417c-8090-2aa417c514dd",
        "trusted": false
      },
      "cell_type": "code",
      "source": "target_train=train['is_iceberg']\nX_train_cv, X_valid, y_train_cv, y_valid = train_test_split(X_train, target_train, random_state=1, train_size=0.75)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "4e6dab11165b7d9515eb32b698851b260f0d941f",
        "_cell_guid": "d6bb750a-e882-4429-ad23-4392389f427f",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Without denoising, core features.\nimport os\ngmodel=getModel()\ngmodel.fit(X_train_cv, y_train_cv,\n          batch_size=24,\n          epochs=50,\n          verbose=1,\n          validation_data=(X_valid, y_valid),\n          callbacks=callbacks)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "04da75db4d60b76ae357503ea1178808e1026b56",
        "_cell_guid": "923850b1-707e-41e7-bdcb-b5d0633fb12f"
      },
      "cell_type": "markdown",
      "source": "###Though the score may be different here,  it works good on LB, I got 0.210 score."
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "0fa65f37d198cd6301376f179d9de0ccc1d40db3",
        "_cell_guid": "079f0a8d-d2a5-4154-b37f-b425333e4ada",
        "trusted": false
      },
      "cell_type": "code",
      "source": "gmodel.load_weights(filepath=file_path)\nscore = gmodel.evaluate(X_valid, y_valid, verbose=1)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "27f021784da863a2ad960a96b9c7394f25521802",
        "_cell_guid": "7cae1458-a566-4714-8b80-0b23fe88509c",
        "trusted": false
      },
      "cell_type": "code",
      "source": "\nX_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\nX_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\nX_test = np.concatenate([X_band_test_1[:, :, :, np.newaxis]\n                          , X_band_test_2[:, :, :, np.newaxis]\n                         , ((X_band_test_1+X_band_test_2)/2)[:, :, :, np.newaxis]], axis=-1)\npredicted_test=gmodel.predict_proba(X_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "b34412c33fe8250df3285867d9a13e4bd08e8c12",
        "_cell_guid": "da3618f6-6e0a-475c-a390-7e17f5406c1a",
        "trusted": false
      },
      "cell_type": "code",
      "source": "submission = pd.DataFrame()\nsubmission['id']=test['id']\nsubmission['is_iceberg']=predicted_test.reshape((predicted_test.shape[0]))\nsubmission.to_csv('sub.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "741f9696d91da6af29266fb199a6c2fb80d26dfe",
        "_cell_guid": "a5140949-c867-43fd-baba-49e57bec44cf"
      },
      "cell_type": "markdown",
      "source": "#### 결론\n점수를 올리기 위해, 나는 Speckle filtering, Indicence angle normalization, 그리고 다른 preprocessing을 사용해 봤지만 잘 작동하지 않았습니다. 당신도 해보고 결과를 내볼수는 있겠지만, 나의 경우엔 그것들이 좋은 결과를 내지는 않았다.\n\n이 kernel을 이용해서 상위 10명 안에 들지는 못할것이니, 좋은 정보를 하나 주겠습니다. test dataset에 8000개의 이미지가 포함되어있고, 우리는 그것을 활용해 볼 수 있습니다. 에측 정확도를 올리기 위해 pseudo labeling을 할 수 있습니다. 여기 관련 글이 있습니다:\nhttps://towardsdatascience.com/simple-explanation-of-semi-supervised-learning-and-pseudo-labeling-c2218e8c769b\n\n이 kernel이 좋았으면 Upvote해주세요.\n\n#### Conclusion\nTo increase the score, I have tried Speckle filtering, Indicence angle normalization and other preprocessing and they don't seems to work.  You may try and see but for me they are not giving any good results.\n\nYou can't be on top-10 using this kernel, so here is one beautiful peice of information. The test dataset contain 8000 images, We can exploit this. We can do pseudo labelling to increase the predictions. Here is the article related to that:\nhttps://towardsdatascience.com/simple-explanation-of-semi-supervised-learning-and-pseudo-labeling-c2218e8c769b\n\nUpvote if you liked this kernel."
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "962411dc0d6a00c1730bfd22767542210c36f751",
        "_cell_guid": "637e3662-38ac-4fa6-8065-48c8105026a9",
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}